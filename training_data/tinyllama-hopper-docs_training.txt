Publicada usando o Documentos Google
Denunciar abusoSaiba mais
Instructions | Hopper V2 RLHF
Atualizado automaticamente a cada 5 minutos

Instructions | Hopper V2 RLHF

üèì Table of Contents
1Ô∏è‚É£ Section 1: Welcome to Hopper V2 RLHF!
2Ô∏è‚É£ Section 2: Ground Rules!
3Ô∏è‚É£ Section 3: Writing Prompts!
4Ô∏è‚É£ Section 4: Proofreading and Fact-Checking
5Ô∏è‚É£ Section 5: Rating Responses
6Ô∏è‚É£ Section 6: Fixing + Improving Responses
NOTE: NO LEETCODE QUESTIONS ALLOWED; NO LLM USAGE ALLOWED. YOU WILL BE DISABLED !!!!
1Ô∏è‚É£ Section 1: Welcome to Hopper V2 RLHF!
In this project, your work will help improve some of the world‚Äôs leading AI models! Here, we‚Äôll go through the steps of your tasks and explain what you‚Äôll be doing in each one.

TASK OVERVIEW
1Ô∏è‚É£
2Ô∏è‚É£
3Ô∏è‚É£
4Ô∏è‚É£
Write a coding prompt in your native language
Proofread the AI responses and check their solutions
Rate each model‚Äôs performance and write justifications
(If applicable) Improve/rewrite one of the responses


üçé What should you know after finishing this section?
Learn what this project is about
Understand what you will have to do in a task
 


Step 1: Review Your Assigned Language and Locale üì¶
Language: You‚Äôll be given a specific language and locale.
Purpose: We are teaching the model to answer code questions in a variety of languages so that it can perform well all over the world!
Why This Matters: Covering many topics makes the AI useful for people with different needs and interests. Your careful work here helps make the model more versatile! Keep in mind the locale and scripture you have been assigned. Write the prompt in the assigned scripture e.g. Hi-IN should be written in Devanagri scripture whereas Hi-LATN should be written in Latin (standard english) scripture.

Step 2: Write a Prompt ‚úçÔ∏è
What is a Prompt?: A prompt is a code question that you write. It tells the AI what to talk about and how to respond.
Key Point: Your prompt is the foundation of this task.
Complexity: prompts need to make the model REASON, a good prompt would have the necessary complexity to make at least one of the responses fail in any of the dimensions.

Step 3: Review Two AI Responses and Complete Two Jobs üîç
Now, the AI will respond to your prompt twice. You‚Äôll review both responses carefully. You have two main tasks:
Code-Checking:
Did the model provide the correct final answer? Test whether the response provided the correct final answer.
Did the model write out any incorrect steps or make incorrect reasoning steps? Once the model generates a response to your prompt, review it carefully. Identify areas where the response falls short or makes mistakes. If one of the models does not have an issue, edit your prompt and try again until you make the model fail
Proofreading:
Think of yourself as the ‚Äúlanguage expert.‚Äù
Check for any unnatural language, awkward phrasing, or grammar errors in your language.
The AI might not speak your language perfectly, so look out for things that sound odd or don‚Äôt flow well.
Did it follow instructions correctly? Check that the AI stayed within the constraints and didn‚Äôt make mistakes.
Is the information accurate? The AI sometimes gets facts wrong, so make sure everything is true and correct.

Step 4: Rate the Responses üßë‚Äç‚öñÔ∏è
After proofreading and fact-checking, you will rate each response based on how well it performed. Here‚Äôs what to keep in mind:
Provide a Justification: Your explanation helps the AI understand what it did wrong.
Side-by-Side Rating: If asked, compare both responses and select the better one. Explain why the chosen response is stronger or more accurate. A high-quality explanation helps improve the model.

Step 5: Improve the Selected Response üé®
Finally, if the selected response has errors, you will have to edit to make it better. Here‚Äôs what to do:
Fix code errors: correct the incorrect step(s) clearly and concisely. The rewrite should be self-contained and understandable, following a logical sequence of reasoning.
Correct Language Errors: Fix any grammar mistakes, spelling errors, or any fluency issues.
Follow Instructions Precisely: Ensure that the AI‚Äôs response matches all instructions perfectly.
All Claims are Accurate: Make sure everything the model says is true and accurate.
Following these steps carefully will make a real difference in improving AI quality. Your attention to detail, accuracy, and fluency help create a model that is more helpful for everyone!
This instructions document will explain every step above in detail to make sure your tasks are high quality!

2Ô∏è‚É£ Section 2: Ground Rules!
To stay on this project, please follow these important rules. Not following them may lead to removal:
Code Prompts Only:
This is a code project. The purpose is to ask coding-related questions.
Assigned Language Only:
Only use the assigned language for your prompts. No English is allowed in any prompt or response unless specifically required.
        Stick to your assigned topic:
Prompts are organized into 7 distinct topics to cover different aspects of the coding process.
No External Language Models (LLMs):
Do not use other AI tools, like ChatGPT or Gemini, to generate text or get ideas. These tools often make mistakes, which can lower your work quality.
Check for Local Language Quality:
Make sure all responses sound natural and fluent for a native speaker in your language.
Carefully Proofread Every Response:
Fact-check everything in the responses and make sure the writing quality sounds like a local person who is native in the language you speak in.
Proofread all spelling, grammar, phrases, flow, ideas, and instruction following components of the response every single time
By following these ground rules, you‚Äôll ensure high-quality work and avoid any quality flags. Thank you for helping improve the AI model!
3Ô∏è‚É£ Section 3: Writing Prompts!
üçé What should you know after finishing this section?
What a user prompt is?
What a good user prompt looks like
When to re-try your user prompt?




üß† Concept: What is a user prompt?
A user prompt is a coding-related question that guides the AI on what to say and how to say it. A good prompt has these elements:
Clear about what the response is asking for:
What it is: The background or main topic that tells the model what the response should answer.
The prompt must be clear about what needs to be solved. You must ask the model something that another human would also be able to understand.
Solvable:
Avoid prompts that don't contain the information necessary to solve them.
Avoid problems containing terms or concepts that do not adhere to coding rules



What is a Topic? üéØ
Prompts are organized into 7 distinct topics to cover different aspects of the coding process. Each prompt is assigned one topic only, which you must align with when creating your prompt.


Topic
Definition
What to Do
What it‚Äôs NOT
Code Generation üíª
Ask for code solutions to a specific problem or algorithm.
Specify the problem, desired functionality, programming language, inputs, outputs, and constraints.‚ö°Ô∏èNote: Input Prompt does not require a code snippet; Model's responses should generate a code snippet (deduct rating if it does not)
Not about analyzing or fixing code.
Problem Reflection ü§î
Analyze a problem, break it down, and evaluate different approaches.
Encourage critical thinking, multiple perspectives, and analysis of strengths/weaknesses. ‚ö°Ô∏èNote: Input Prompt might contain a code snippet; Model's responses might generate a code snippet
Not about providing a single "correct" answer or writing code.
Tests Reasoning üß™
Explain the reasoning behind test case results and edge cases.
Provide test cases and ask for an explanation of why specific results occurred. ‚ö°Ô∏èNote: Input Prompt must contain a code snippet; Model's responses might generate a code snippet
Not about generating tests or writing new code.
Code Refactoring üõ†Ô∏è
Improve existing, functional code for readability, performance, or maintainability.
Provide code to refactor, specify areas to improve (e.g., readability, performance, documentation). ‚ö°Ô∏èNote: Both Input Prompt requires a code snippet; Model's responses should generate a code snippet (deduct rating if it does not)
Not about fixing broken code.
Bug Fixing üêõ
Debug and correct broken code.
Present broken code with a description of intended functionality and ask for corrections. ‚ö°Ô∏èNote: Input Prompt requires a code snippet; Model's responses should generate a code snippet (deduct rating if it does not)
Not about improving working code.
Test Generation ‚úÖ
Create test cases for code, covering normal scenarios, edge cases, and errors.
Provide code to be tested, specify the type of tests needed (e.g., unit, integration), and aim for broad test coverage. ‚ö°Ô∏èNote: Input Prompt must contain code snippet; Model's responses should generate a code snippet (deduct rating if it does not)
Not about analyzing existing test results.
Solution Reasoning üí°
Analyze how a solution or algorithm works and discuss its properties.
Provide a solution and ask for step-by-step analysis, including efficiency, correctness, and limitations. ‚ö°Ô∏èNote: Input Prompt requires a code snippet; Model's responses might generate a code snippet
Not about writing new code or debugging.


Important Notes:
Distinctions Between Topics:
Refactoring vs. Bug Fixing: Refactoring works with functional but suboptimal code, while Bug Fixing focuses on broken code.
Tests Reasoning vs. Solution Reasoning: Tests Reasoning explains test case outputs, while Solution Reasoning evaluates how a solution works.
Key Best Practices:
Be clear and concise, avoiding ambiguity.
Provide enough context for the task.
Follow assigned topic instructions precisely.
                                                                                                                      


4Ô∏è‚É£ Section 4: Proofreading and Fact-Checking
üçé What should you know after finishing this section?
Understand that you need to be a proofreader
You are an expert on how your language should be spoken and written
The model makes a lot of fluency mistakes, spelling/grammar errors, or awkward phrasing. You need to find all of these!
Recognize that you also need to be a code-expert
The model makes many errors in its reasoning, understanding prompt instructions, or solving code questions
Your job is to catch all these errors and fix them if they‚Äôre present in the final response



Here‚Äôs how to do this:
Criteria
Rubric
Coding
Localization
1 ‚Äì Major Issues
2 ‚Äì Minor Issues
3 - No Issues
The extent to which the response is localized with respect to culture and language nuances of the prompt language
Instruction Following
1 ‚Äì Major Issues
2 ‚Äì Minor Issues
3 - No Issues
The extent to which the response addresses the implicit and explicit instructions in the prompt.
Truthfulness
1 ‚Äì Major Issues
2 ‚Äì Minor Issues
3 - No Issues
The extent to which the claims in the response are truthful and correct, and the code is executable and produces correct outputs.
Output correctness may not be measured if, for example, the code only functions when embedded inside a large, complex program that is not provided, or if it requires an external file/API dependency that is not provided.
Response Length
-2 ‚Äì Too Short
-1 ‚Äì A Little Short
0 ‚Äì Just Right
1 ‚Äì A Little Verbose
2 ‚Äì Too Verbose
The extent to which a solution optimizes the number of steps,  neither being too excessive or too short (terse).
Style and Clarity
1 ‚Äì Major Issues
2 ‚Äì Minor Issues
3 - No Issues
The extent to which code explanation is well-structured and visually organized, includes necessary documentation aiding in code understanding, and the code is readable employing proper formatting and mnemonic variable and function names.
Harmlessness
1 ‚Äì Major Issues
2 ‚Äì Minor Issues
3 - No Issues
The extent to which a response could be interpreted as unsafe.
Satisfaction
5 ‚Äì Highly satisfying
4 ‚Äì Slightly satisfying
3 ‚Äì Okay
2 ‚Äì Slightly unsatisfying
1‚Äì Highly unsatisfying
The combination of issues identified in the response.


5Ô∏è‚É£ Section 5: Rating Responses
üçé What should you know after finishing this section?
What is the role of rating?
What do you need to watch out for when rating?
What is a justification



üß† Concept: Rating
The rating aspect is simply marking which items the response ‚Äúchecks off‚Äù. This is the simplest part of the task, but one that needs the closest attention to detail.
Your rating will be linked to the proofreading and fact-checking we discussed in the previous section. You will do two types of rating:
Dimension Ratings
Each response will be individually rated on:
Fluency & Localization
Instruction Following
Truthfulness
Writing Style and Clarity
Verbosity
Side-by-side Rating
You will select the better response and justify why
Any task that doesn‚Äôt perform correct ratings risks a low quality score, so please do not rush through this section!


üîé Dimension Ratings
Once you‚Äôve identified that one of the responses has errors, you will need to rate both responses on a scale of 1-3 for each criterion, with 3 being the highest score. Here are the categories to focus on:

Instruction Following
Implicit Instructions: Does the response address implied instructions from the prompt?
Explicit Instructions: Does the response follow directly stated requirements in the prompt?
Overall Adherence: Does the response meet all the requirements both implicit and explicit?
Localization
Cultural Nuances: Does the response reflect cultural norms and sensitivities of the prompt's context?
Language Adaptation: Is the response adapted appropriately to the language used in the prompt?
Truthfulness
Claim Accuracy: Are all claims and details in the response factually correct?
Logical Steps: Are reasoning steps valid and error-free?
Verbosity
Optimal Length: Is the response neither too terse nor overly verbose?
Efficiency: Does the solution optimize the number of steps while being complete?
Style and Clarity
Readability: Is the response easy to read and understand?
Structure: Is the response well-structured and visually organized?
Formatting: Does the response use appropriate formatting tools like lists or markdown to enhance clarity?

‚öñÔ∏è Side by Side Rating
Selecting the Better Response
After reading both responses, you‚Äôll choose which one is better using the following options:
Response A is much better: Choose this if Response A is significantly better, or if Response B has major issues (e.g., wrong language, gibberish, incomplete).
Response A is better: Choose this if Response A performs better in most rating criteria, especially the key ones like accuracy, completeness, and fluency.
Response A is slightly better: Choose this if Response A is only a little better in one or two criteria.
Tie: Choose this if both responses are of similar quality across all dimensions or have individual strengths that balance out.
The same options apply for Response B if it‚Äôs better.

Hierarchy of Rating Dimensions
When deciding which response is better, some criteria are more important than others. Here‚Äôs the priority order:
Truthfulness üéñÔ∏è (most important)
Instruction Following üéñÔ∏è (also most important)
Language Fluency
Writing Style & Clarity
Verbosity

Writing a Justification for Your Choice
Your justification explains why you chose one response over the other. Here are the key points to keep in mind:
Stick to the Evidence: Focus on the main differences between the two responses. No need to mention criteria that don‚Äôt have issues.
Focus on Key Criteria: Only discuss the dimensions that affected your choice (e.g., if Truthfulness was a big difference, mention that).
Be Concise: Avoid flowery language or extra details that aren‚Äôt needed.
Depth and Completeness Matter: It‚Äôs better to focus on the quality and accuracy of information over writing style or formatting.
Don‚Äôt Use LLMs: Write your justification independently.

6Ô∏è‚É£ Section 6: Fixing + Improving Responses
üçé What should you know after finishing this section?
What to fix in a rewrite
The importance of having no code or fluency  issues whatsoever in the fixed response


After you complete selecting the preferred response and give a justification for your preference score, you will be asked to answer a few questions. These questions will determine if a writing  step is needed.
Unless the response you selected is perfect and has no issues at all, you are expected to fix and improve the selected response so that it doesn‚Äôt have any code or language issues. A perfect response should be accurate and fully aligned with the prompt‚Äôs requests and constraints. Fixing a response is composed of three major steps.

Step 1: Truthfulness üéØ
Review claims, code steps, and reasoning: The response should be correct from a coding perspective and have proper reasoning based on information in the prompt or appropriate principles. If there are any errors in the original response, they should be corrected in your perfect response.
How to Rewrite:
If the original response had incorrect information, rewrite it with the correct information embedded naturally.
Maintain Sequential Integrity: Ensure that your rewrite preserves the logical order of the original reasoning and includes the same level of detail.
Clarity in Rewriting: Rewrite the step clearly and concisely, using simple language that avoids jargon. The rewrite should be self-contained and understandable, following a logical sequence of reasoning.
Focus on Problem-Solving: Only include information necessary to solve the problem. Do not add extraneous details like definitions of basic concepts.
What to Look For: Check that all the facts presented are correct.

Step 2: Instruction Following üìè
Compare to the Prompt: The perfect response should exactly follow the instructions provided in the prompt. This includes adhering to any constraints like format, length, structure, or content requirements.
How to Rewrite: If the initial response deviates from the instructions (e.g., exceeds word count or fails to meet the format), revise it to strictly follow the original guidelines.

Step 3: Improve the response‚Äôs fluency and style üí¨
Think of yourself as the ‚Äúlanguage expert.‚Äù
Check for any unnatural language, awkward phrasing, or grammar errors in your language.
The AI might not speak your language perfectly, so look out for things that sound odd or don‚Äôt flow well.
Ensure that the model use the tone specified in the prompt and the the tone is respectful of cultural context
The response should not have any awkward phrasing or language errors EVER!

Examples of a good prompt ü§ì
Code Generation:
"Generate Python code for a program that simulates a basic banking system. The program should allow users to create new accounts, deposit and withdraw funds, and check their account balance. Ensure the code includes error handling for invalid inputs (e.g., negative deposit amounts) and uses appropriate data structures to store account information. The code should be well-documented with comments explaining the functionality of each part."
"Implement a graph traversal algorithm in Java that identifies the shortest path between two nodes in a weighted, directed acyclic graph. The graph can be represented using an adjacency list. The algorithm should have a time complexity of O(V+E), where V is the number of vertices and E is the number of edges. Include a main method that demonstrates the usage of the algorithm with a sample graph and two nodes."
Problem Reflection:
"Analyze the challenges of implementing a concurrent system with multiple threads accessing shared resources. Discuss potential issues like race conditions and deadlocks. Explore different synchronization mechanisms (e.g., mutexes, semaphores) and their trade-offs in terms of complexity and performance. How can these mechanisms be used to ensure data integrity and prevent concurrency-related bugs?"
"Consider the problem of designing an efficient caching system for a web application. What are the key factors to consider when choosing a caching strategy (e.g., eviction policies, cache size, consistency)? Discuss the advantages and disadvantages of different caching techniques, such as LRU (Least Recently Used), FIFO (First-In, First-Out), and LFU (Least Frequently Used). How can you measure the effectiveness of a caching system?"
Tests Reasoning:
"You are given a function that implements a binary search algorithm on a sorted array. The following test cases are provided:
Input array: [2, 5, 8, 12, 16, 23, 38, 56, 72, 91], Target value: 23, Output: 5 (index of the target value)
Input array: [2, 5, 8, 12, 16, 23, 38, 56, 72, 91], Target value: 4, Output: -1 (target value not found)
Input array: [1], Target value: 1, Output: 0
Explain why the binary search algorithm produces these outputs for each of the given test cases. How does the algorithm handle cases where the target value is not present in the array? What is the time complexity of binary search and why is it efficient for searching sorted data?"
"Consider a machine learning model trained to classify images of cars and bikes. You are given the following test images and the model's predictions:
Image 1: A clear picture of a car, Prediction: car (correct)
Image 2: A blurry picture of a bike, Prediction: bike (correct)
Image 3: A picture of a car surrounded by bikes, Prediction: bike (incorrect)
Analyze the model's predictions and explain why it might have misclassified the image of the car with a bike. What factors could be influencing the model's decision? How can you improve the model's accuracy in such cases?"
Code Refactoring:

Example 1+++++++++++++++++
"Refactor the following Java code that calculates the area of different geometric shapes. The code currently uses a long series of if-else statements to determine the shape type. Improve the code by using polymorphism and abstract classes or interfaces to represent different shapes. Ensure the refactored code is more maintainable, extensible, and adheres to object-oriented design principles."
// Existing code to be refactored
public class AreaCalculator {
    public double calculateArea(String shapeType, double‚Ä¶ dimensions) {
        if (shapeType.equals(‚Äúcircle‚Äù))
            // Calculate area of circle
        } else if (shapeType.equals(‚Äúrectangle‚Äù)) {
            // Calculate area of rectangle
        } else if (shapeType.equals(‚Äútriangle‚Äù)) {
            // Calculate area of triangle
        } // ‚Ä¶ more else-if statements for other shapes
        return 0;
    }
}
Example 2++++++++++++++++
‚ÄúYou are given Python code that implements a simple web server using sockets. The code works correctly but lacks proper error handling and logging. Refactor the code to include robust error handling for potential exceptions, such as network errors and invalid requests. Add logging statements to record important events, like client connections, requests, and errors. Ensure the refactored code is more reliable and easier to debug.‚Äù
def longest_common_subsequence(str1, str2):
  ‚Äú‚Äù"
  Finds the longest common subsequence of two strings (BUGGY!).
  Args:
    str1: The first string.
    str2: The second string.
  Returns:
    The longest common subsequence as a string.
  ‚Äú‚Äù"
  m = len(str1)
  n = len(str2)
  # Initialize a 2D array INCORRECTLY (should be (m+1) x (n+1))
  dp = [[0] * n for _ in range(m)]
  for i in range(1, m + 1):
    for j in range(1, n + 1):
      if str1[i-1] == str2[j-1]:
        dp[i][j] = dp[i-1][j-1] + 1  # IndexError due to incorrect initialization
      else:
        dp[i][j] = max(dp[i-1][j], dp[i][j-1])  # IndexError here as well
  # Backtracking with the same bug as before
  i = m
  j = n
  lcs = ‚Äú‚Äù
  while i > 0 and j > 0:
    if str1[i-1] == str2[j-1]:
      lcs = str1[i-1] + lcs
      i -= 1
      j -= 1
    else:
      if dp[i-1][j] > dp[i][j-1]:  # Incorrect comparison
        i -= 1
      else:
        j -= 1
  return lcs
Bug Fixing:
Example 1 +++++++++++++++
"A Java program that implements a multithreaded chat application is experiencing intermittent crashes. The crashes seem to occur randomly when multiple users are sending messages simultaneously. Analyze the code and identify the potential race conditions or synchronization issues that might be causing these crashes. Provide a corrected version of the code that addresses these concurrency problems and ensures thread safety."
import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.PrintWriter;
import java.net.ServerSocket;
import java.net.Socket;
import java.util.ArrayList;
import java.util.List;
public class ChatServer {
  private List<PrintWriter> clientWriters = new ArrayList<>();
  public void start(int port) throws IOException {
    ServerSocket serverSocket = new ServerSocket(port);
    System.out.println("Chat server started on port " + port);
    while (true) {
      Socket clientSocket = serverSocket.accept();
      System.out.println("New client connected");
      // BUG: No synchronization when accessing shared clientWriters list
      clientWriters.add(new PrintWriter(clientSocket.getOutputStream(), true));
      Thread clientThread = new Thread(() -> {
        try {
          BufferedReader reader = new BufferedReader(new InputStreamReader(clientSocket.getInputStream()));
          String message;
          while ((message = reader.readLine()) != null) {
            // BUG: No synchronization when accessing shared clientWriters list
            for (PrintWriter writer : clientWriters) {
              writer.println(message);
            }
          }
        } catch (IOException e) {
          System.err.println("Error handling client: " + e.getMessage());
        }
      });
      clientThread.start();
    }
  }
  public static void main(String[] args) throws IOException {
    ChatServer server = new ChatServer();
    server.start(8080);
  }
}
Example 2+++++++++++++++++
"This Python code is supposed to find the longest common subsequence of two strings, but it's returning incorrect results for some inputs. Debug the code and identify the source of the error. Provide a corrected version of the code that produces the correct output for all valid input strings. Explain the bug you fixed and how your correction addresses the issue."
def longest_common_subsequence(str1, str2):
 """
 Finds the longest common subsequence of two strings (BUGGY!).
 Args:
  str1: The first string.
  str2: The second string.
 Returns:
  The longest common subsequence as a string.
 ‚Äú‚Äù"
 m = len(str1)
 n = len(str2)
 # Initialize a 2D array with INCORRECT dimensions
 dp = [[0] * n for _ in range(m)]  
 for i in range(m): # Looping up to m instead of m+1
  for j in range(n): # Looping up to n instead of n+1
   if str1[i] == str2[j]: # Comparing characters at incorrect indices
    dp[i][j] = dp[i-1][j-1] + 1 # Potential IndexError due to incorrect loop bounds
   else:
    dp[i][j] = max(dp[i-1][j], dp[i][j-1]) # Potential IndexError here as well
 # Backtracking with incorrect indices and logic
 i = m - 1  
 j = n - 1
 lcs = ‚Äú‚Äù
 while i >= 0 and j >= 0: # Incorrect loop condition
  if str1[i] == str2[j]: # Comparing characters at incorrect indices
   lcs = str1[i] + lcs
   i -= 1
   j -= 1
  else:
   if dp[i-1][j] > dp[i][j-1]: # Incorrect comparison and potential IndexError
    i -= 1
   else:
    j -= 1
 return lcs
Test Generation:
I'm a software engineer student and I started to study unit test in Java. The following Java function calculates the Fibonacci number at a specific position.
public class FibSequence {
    public static int fib(int n) {
     
        if (n == 0)
            return 0;
        if (n == 1)
            return 1;
        if (n < 0) {
            throw new IllegalArgumentException("n cannot be negative.");
        }
        int a = 0, b = 1, result = 0;
        for (int counter = 2; counter <= n; counter++) {
            result = a + b;
            a = b;
            b = result;
        }
        return result;
    }
}
I want to create test cases to cover my function whole FibSequence function.
Solutions Reasoning:

"You are given a JavaScript implementation of a sorting algorithm called Merge Sort. Explain step-by-step how this algorithm works to sort an array of numbers. Analyze its time and space complexity in comparison to other sorting algorithms, such as Bubble Sort and Quick Sort. Discuss the advantages and disadvantages of Merge Sort, including its suitability for different types of data and use cases."
function mergeSort(arr) {
 if (arr.length <= 1) {
  return arr;
 }
 const mid = Math.floor(arr.length / 2);
 const left = arr.slice(0, mid);
 const right = arr.slice(mid);
 return merge(mergeSort(left), mergeSort(right));
}
function merge(left, right) {
 let result = [];
 let leftIndex = 0;
 let rightIndex = 0;
 while (leftIndex < left.length && rightIndex < right.length) {
  if (left[leftIndex] < right[rightIndex]) {
   result.push(left[leftIndex]);
   leftIndex++;
  } else {
   result.push(right[rightIndex]);
   rightIndex++;
  }
 }
 return result.concat(left.slice(leftIndex)).concat(right.slice(rightIndex));
}
// Example usage:
const unsortedArray = [5, 2, 4, 6, 1, 3];
const sortedArray = mergeSort(unsortedArray);
console.log(sortedArray); // Output: [1, 2, 3, 4, 5, 6]
Example 2 ++++++++++++++++++++
‚ÄúAnalyze the following C# code that implements a data structure called a Trie. Explain how this data structure efficiently stores and retrieves a large collection of strings. Discuss its use cases, such as autocomplete functionality and spell checking. Compare the performance of a Trie with other data structures, like hash tables and balanced trees, for storing and searching strings. What are the strengths and weaknesses of using a Trie in different scenarios?‚Äù
public class TrieNode
{
  public char Value { get; set; }
  public bool IsEndOfWord { get; set; }
  public Dictionary<char, TrieNode> Children { get; set; }
  public TrieNode(char value)
  {
    Value = value;
    IsEndOfWord = false;
    Children = new Dictionary<char, TrieNode>();
  }
}
public class Trie
{
  private TrieNode root;
  public Trie()
  {
    root = new TrieNode(‚Äò\0‚Äô); // Root node with null character
  }
  public void Insert(string word)
  {
    TrieNode currentNode = root;
    foreach (char c in word)
    {
      if (!currentNode.Children.ContainsKey¬©)
      {
        currentNode.Children.Add(c, new TrieNode¬©);
      }
      currentNode = currentNode.Children[c];
    }
    currentNode.IsEndOfWord = true;
  }
  public bool Search(string word)
  {
    TrieNode currentNode = root;
    foreach (char c in word)
    {
      if (!currentNode.Children.ContainsKey¬©)
      {
        return false;
      }
      currentNode = currentNode.Children[c];
    }
    return currentNode.IsEndOfWord;
  }
}
// Example usage:
Trie trie = new Trie();
trie.Insert(‚Äúapple‚Äù);
trie.Insert(‚Äúapp‚Äù);
trie.Insert(‚Äúbanana‚Äù);
Console.WriteLine(trie.Search(‚Äúapple‚Äù)); // Output: True
Console.WriteLine(trie.Search(‚Äúapp‚Äù));   // Output: True
Console.WriteLine(trie.Search(‚Äúban‚Äù));   // Output: False





Projeto: Hopper V2
Dura√ß√£o das tasks: 60 minutos de tempo pago, 2 horas totais, a princ√≠pio.
N√∫mero de turnos: 1.
Objetivo: Escrever um prompt que se adeque a categoria pr√©-estabelecida com complexidade suficiente para que ao menos 1 das respostas do modelo falhem (em qualquer dimens√£o)
Documenta√ß√£o oficial: https://docs.google.com/document/d/e/2PACX-1vTG1Op3O-J43chncV-9U7pKPB0lpGY3eq83zT3J8V7XV4DDwrzcy_78-31JwPSx94Bnb2izIFlx5rrk/pub


Gotchas:
Prompts auto-contidos:
Quando dizemos que os prompts devem ser "auto-contidos", queremos dizer que toda a informa√ß√£o necess√°ria para entender e resolver a tarefa precisa estar inclu√≠da no pr√≥prio prompt. Em outras palavras:
Incluir o C√≥digo Relevante: Se voc√™ deseja que o modelo analise ou modifique seu c√≥digo, forne√ßa o trecho exato do c√≥digo, em vez de referenciar arquivos externos.
Fornecer Esquemas de API: Se deseja interagir com uma API, inclua o esquema ou a documenta√ß√£o necess√°ria, assim o modelo saber√° quais endpoints e par√¢metros est√£o dispon√≠veis.
Evitar Depend√™ncias Pessoais ou Inacess√≠veis: N√£o presuma que o modelo tenha acesso a bases de conhecimento pessoais (por exemplo, colando apenas um arquivo de um projeto que importa e chama fun√ß√µes provenientes de diversos outros arquivos aos quais o modelo n√£o tem acesso). O prompt deve conter todos os detalhes relevantes para garantir que a resposta seja precisa e completa, sem depender de contextos desconhecidos. Isso n√£o significa que voc√™ n√£o possa usar bibliotecas razo√°velmente populares, o modelo deve ter conhecimento destas.
Trabalhe Junto com o Modelo: Se o c√≥digo/resposta que o modelo providenciou est√° incorreto, n√£o delete o c√≥digo/resposta inteiro e come√ße do 0. A ideia √© trabalhar em conjunto, corrigindo apenas o necess√°rio.
Vers√£o da Linguagem:
Informe a vers√£o da linguagem utilizada em situa√ß√µes onde possa haver problemas, como em Java e C#.


Frameworks e Bibliotecas:
Tenha cuidado ao escolher frameworks e bibliotecas para o c√≥digo. Evite riscos que possam levar √† rejei√ß√£o da task, especialmente com ferramentas como Django, Docker ou Makefile, que requerem configura√ß√£o mais extensa ou conhecimento espec√≠fico.


APIs Privadas:
Evite o uso de APIs privadas, como as do Google ou outras que exijam uma chave privada. E, se utilizarem APIs p√∫blicas, mencionem os endpoints utilizados e qual a entrada e sa√≠da esperada. 


Erros Comuns:
Link de refer√™ncia
Falta de c√≥digo em categorias que necessitam c√≥digo
As seguintes categorias necessitam de c√≥digo no prompt:
‚ÄúTest Reasoning‚Äù
‚ÄúCode refactoring‚Äù
‚ÄúBug Fixing‚Äù
‚ÄúTest Generation‚Äù
‚ÄúSolution Reasoning‚Äù
Prompts incorretos nas categorias de reasoning


Para ‚ÄúReasoning‚Äù:
Pedir para o modelo explicar o c√≥digo (ou os testes), solicitando uma an√°lise passo a passo (Solution Reasoning) ou uma explica√ß√£o do porqu√™ de resultados espec√≠ficos nos testes (Test Reasoning).
 Observa√ß√£o: N√£o se deve gerar c√≥digo novo nessas categorias.
Para ‚ÄúTest Generation‚Äù:
 √â importante ter o c√≥digo pronto e requisitar que testes sejam criados.
Dica: Pedir que o modelo crie testes unit√°rios usando frameworks espec√≠ficas (ex.: jest) √© uma maneira f√°cil de faz√™-lo falhar.
C√≥digo n√£o testado


Teste o c√≥digo gerado e cole o output ou erro nos campos apropriados:
Erros ‚Üí campo de error
Output regular ‚Üí campo de standard output
Se a IDE da plataforma n√£o permitir testes, rode o c√≥digo localmente.
Caso n√£o seja poss√≠vel testar, considere usar outro prompt que voc√™ consiga testar; a revis√£o exige garantia de funcionalidade.
Prompt extremamente simples


O c√≥digo precisa ter algum sentido.Por exemplo, N√£o faz sentido testar:
```
function randomNumber() {
  return rand(1,6)
}
```
Esse c√≥digo √© apenas um wrapper para a fun√ß√£o rand, com n√≠vel de complexidade muito baixo, sem utilidade para treinamento.
Ratings gen√©ricos ou de LLM


Mesmo que a tarefa seja aprov√°vel, usar justificativas muito gen√©ricas para os ratings pode resultar em perda de pontos.
Analise a resposta do modelo de forma independente.
Aten√ß√£o: Jamais cole a resposta da LLM diretamente nos campos de ratings, pois isso pode levar √† remo√ß√£o do squad, do projeto ou da Outlier.
Confus√£o entre Instruction Following e Truthfulness


Se o modelo entendeu a instru√ß√£o e tentou cumprir, mas falhou, o problema √© de Truthfulness, n√£o de Instruction Following.
Exemplo:
Pedido: Imprimir ‚ÄúHello, world!‚Äù no console.
Se nada √© impresso (n√£o
 existe `print` no c√≥digo) ‚Üí problema de Instruction Following.Se o modelo menciona que est√° logando, mas n√£o o faz ‚Üí problema de Truthfulness.
Se o c√≥digo falha por erro (ex.: string n√£o fechada: print("Hello, world!)) ‚Üí problema de Truthfulness.
C√≥digo mal formatado no prompt


Sempre inclua c√≥digo dentro de backticks. Exemplo em C++:
		```cpp
		C√≥digo aqui
		```
N√£o consertar a resposta


Se a resposta escolhida como a melhor cont√©m erros, voc√™ deve corrigi-los na reescrita.
Se algum issue foi marcado em algum rating da resposta, √© sua responsabilidade corrigi-lo.
Tome cuidado com esses pontos para aumentar as chances de aprova√ß√£o das suas tasks.


Outline da task:

Ratings:
Instruction Following:
Verifique se o modelo *entendeu* as instru√ß√µes do prompt e *tentou* responder da maneira certa, incluindo requisitos impl√≠citos.
Localization
Verifique se a resposta respeita as caracter√≠sticas culturais (vc pediu um programa para gerenciar um banco e o modelo usou $ ao inv√©s de R$, por exemplo) e est√° na linguagem correta (sem nenhuma palavra em idioma aleat√≥rio)
Truthfulness
Todas as informa√ß√µes est√£o corretas? (o c√≥digo roda? O modelo alucinou na resposta ou inventou alguma coisa que n√£o condiz com a realidade do c√≥digo?)
Verbosity
A resposta est√° equilibrada, sem ser curta demais ou excessivamente longa?
A solu√ß√£o apresenta os passos necess√°rios de forma otimizada e completa?
Style and Clarity
Verifique se a resposta est√° bem estruturada, sem excesso de blocos de c√≥digo soltos (sem markdown por exemplo, ou de maneira confusa)
Legibilidade: A resposta √© f√°cil de ler e entender?
Estrutura: O conte√∫do est√° bem organizado e visualmente claro?
Formata√ß√£o: Foram usados recursos como listas ou markdown para deixar a explica√ß√£o mais clara?
Checklist:
‚úÖ Se no Side by Side rating nenhuma resposta √© melhor do que outra, as duas tem que ter problemas. Se as duas est√£o perfeitas, refa√ßa o prompt.
‚úÖ O prompt n√£o cont√©m um problema do leetcode/hackerrank/etc e n√£o foi descaradamente copiado da internet ou de uma LLM.
‚úÖ Prompt est√° na linguagem correta.
‚úÖ Prompt menciona a linguagem de programa√ß√£o da task.
‚úÖ Prompt est√° na categoria correta.
‚úÖ Se o prompt cont√©m c√≥digo, ele est√° funcionando.
‚úÖ Se a resposta final tiver c√≥digo, ele est√° funcionando corretamente.
‚úÖ A resposta final n√£o cont√©m informa√ß√µes falsas.
‚úÖ A melhor resposta foi selecionada como melhor e os ratings dados pra ela fazem sentido com o rating do side by side.


Exemplos de prompt:
Test Generation:
C++ - PT-PT:
Trabalho como desenvolvedor de jogos para uma grande empresa e criei este c√≥digo em C++ que recebe uma dire√ß√£o, uma velocidade e um tempo em segundos e calcula a posi√ß√£o final de um jogador, num cen√°rio 2D, assumindo que o jogo roda a 60 frames por segundo. No entanto, quero ter a certeza de que est√° a funcionar corretamente; podes criar um conjunto de testes unit√°rios usando Google Test para ele? Certifica-te de fornecer uma cobertura abrangente e que todos os testes passem.

`Implementation.h`
```cpp
#include <iostream>
#include <chrono>
#include <thread>
#include <cmath>
#include <stdexcept>

class Vector2 {
public:
    double x, y;
    Vector2(double x = 0, double y = 0) : x(x), y(y) {}
    Vector2 operator*(double scalar) const { return Vector2(x * scalar, y * scalar); }
    Vector2 operator+(const Vector2& other) const { return Vector2(x + other.x, y + other.y); }
};

Vector2 normalize(const Vector2& vec) {
    double length = std::sqrt(vec.x * vec.x + vec.y * vec.y);
    if (length == 0) throw std::invalid_argument("Direcao invalida (vetor nulo)");
    return Vector2(vec.x / length, vec.y / length);
}

class Player {
public:
    Vector2 position;
    Player(double x = 0, double y = 0) : position(x, y) {}
};

Vector2 movePlayer(Player& player, Vector2 direction, double velocity, double durationSeconds) {
    if (velocity < 0) throw std::invalid_argument("Velocidade nao pode ser negativa");
    if (durationSeconds <= 0) throw std::invalid_argument("Duracao deve ser maior que zero");
    const double fps = 60.0;
    double dt = 1.0 / fps;
    int frames = static_cast<int>(durationSeconds * fps);
    direction = normalize(direction);
    for (int i = 0; i < frames; ++i) {
        Vector2 displacement = direction * velocity * dt;
        player.position = player.position + displacement;
        std::this_thread::sleep_for(std::chrono::milliseconds(16));
    }
    return player.position;
}
```

Code Refactoring
C++ - PT-PT
Sou um programador de jogos a trabalhar num motor de jogo orientado por eventos em C++. O meu sistema atual permite registar e despachar eventos utilizando *type erasure*, mas o c√≥digo n√£o √© modular e √© dif√≠cil de manter. Preciso de uma vers√£o refatorada deste c√≥digo que melhore a modularidade, siga as pr√°ticas modernas de C++ e separe melhor as responsabilidades. Poderias refatorar o seguinte c√≥digo para o tornar mais sustent√°vel e extens√≠vel?
```cpp
#include <iostream>
#include <functional>
#include <unordered_map>
#include <vector>
#include <typeindex>

template<typename Evento>
using Listener = std::function<void(const Evento&)>;

template<typename Evento>
void adicionarListener(
    std::unordered_map<std::type_index, std::vector<std::function<void(const void*)>>>& listeners,
    Listener<Evento> listener
) {
    listeners[std::type_index(typeid(Evento))].push_back(
        [listener](const void* evento) {
            listener(*static_cast<const Evento*>(evento));
        }
    );
}

template<typename Evento>
void despachar(
    const std::unordered_map<std::type_index, std::vector<std::function<void(const void*)>>>& listeners,
    const Evento& evento
) {
    auto it = listeners.find(std::type_index(typeid(Evento)));
    if (it != listeners.end()) {
        for (const auto& listener : it->second) {
            listener(&evento);
        }
    }
}

struct JogadorPontuouEvento {
    int jogadorId;
    int pontos;
};

struct JogoTerminadoEvento {
    bool vitoria;
};

int main() {
    std::unordered_map<std::type_index, std::vector<std::function<void(const void*)>>> listeners;

    adicionarListener<JogadorPontuouEvento>(listeners, [](const JogadorPontuouEvento& e) {
        std::cout << "Jogador " << e.jogadorId << " marcou " << e.pontos << " pontos.\n";
    });

    adicionarListener<JogoTerminadoEvento>(listeners, [](const JogoTerminadoEvento& e) {
        std::cout << (e.vitoria ? "Vit√≥ria!" : "Derrota!") << "\n";
    });

    despachar(listeners, JogadorPontuouEvento{1, 150});
    despachar(listeners, JogoTerminadoEvento{false});

    return 0;
}
```

Code Generation
C++ - PT-PT
Sou designer de jogos e estou a estudar m√°quinas de estados, mas tenho dificuldades em implement√°-las em C++, especialmente depois de descobrir o polimorfismo. Poderia fornecer um exemplo detalhado de uma m√°quina de estados implementada em C++ utilizando o padr√£o de design State com polimorfismo? Preciso de uma m√°quina de estados que inclua os seguintes estados:

* Inativo  
* A correr  
* Em pausa  
* Terminado

com transi√ß√µes entre estes estados baseadas na entrada do utilizador. O exemplo deve incluir uma fun√ß√£o `main` onde o utilizador possa introduzir comandos para alterar os estados.Inclua coment√°rios que expliquem o c√≥digo e a l√≥gica por detr√°s de cada transi√ß√£o.


Bug Fixing
C++ -  PT-PT (neste caso o erro est√° na condicional if (failed) que deveria ser `if (!failed)`).
Sou um desenvolvedor de jogos e estou a trabalhar num prot√≥tipo de um jogo roguelike em C++. De momento, estou a desenvolver um gerador de mapas que cria v√°rias salas e as conecta atrav√©s de corredores. Como se trata de um prot√≥tipo, todo o mapa √© representado por caracteres ASCII.

Infelizmente, o meu c√≥digo n√£o est√° a funcionar corretamente, embora compile. Sempre que o executo, o mapa gerado consiste apenas de paredes ('#') sem qualquer corredor ou sala.

Poderia corrigir este erro para mim?

Aqui est√° o meu c√≥digo:
```cpp
#include <iostream>
#include <vector>
#include <cstdlib>
#include <ctime>
#include <algorithm>

using namespace std;

const int WIDTH = 80;
const int HEIGHT = 25;
const int MAX_ROOMS = 10;
const int ROOM_MIN_SIZE = 4;
const int ROOM_MAX_SIZE = 10;

struct Room {
    int x, y, width, height;
    int centerX() const { return x + width / 2; }
    int centerY() const { return y + height / 2; }
};

bool intersects(const Room& a, const Room& b) {
    return (a.x <= b.x + b.width && a.x + a.width >= b.x &&
            a.y <= b.y + b.height && a.y + a.height >= b.y);
}

int main() {
    srand(static_cast<unsigned int>(time(0)));

    vector<vector<char>> dungeon(HEIGHT, vector<char>(WIDTH, '#'));
    vector<Room> rooms;

    for (int i = 0; i < MAX_ROOMS; i++) {
        int w = ROOM_MIN_SIZE + rand() % (ROOM_MAX_SIZE - ROOM_MIN_SIZE + 1);
        int h = ROOM_MIN_SIZE + rand() % (ROOM_MAX_SIZE - ROOM_MIN_SIZE + 1);
        int x = rand() % (WIDTH - w - 1) + 1;
        int y = rand() % (HEIGHT - h - 1) + 1;

        Room newRoom { x, y, w, h };

        bool failed = false;
        for (const auto& other : rooms) {
            if (intersects(newRoom, other)) {
                failed = true;
                break;
            }
        }
        if (failed) {
            for (int row = y; row < y + h; row++) {
                for (int col = x; col < x + w; col++) {
                    dungeon[row][col] = '.';
                }
            }

            if (!rooms.empty()) {
                int prevCenterX = rooms.back().centerX();
                int prevCenterY = rooms.back().centerY();
                int newCenterX = newRoom.centerX();
                int newCenterY = newRoom.centerY();

                if (rand() % 2) {
                    for (int col = min(prevCenterX, newCenterX); col <= max(prevCenterX, newCenterX); col++) {
                        dungeon[prevCenterY][col] = '.';
                    }
                    for (int row = min(prevCenterY, newCenterY); row <= max(prevCenterY, newCenterY); row++) {
                        dungeon[row][newCenterX] = '.';
                    }
                } else {
                    for (int row = min(prevCenterY, newCenterY); row <= max(prevCenterY, newCenterY); row++) {
                        dungeon[row][prevCenterX] = '.';
                    }
                    for (int col = min(prevCenterX, newCenterX); col <= max(prevCenterX, newCenterX); col++) {
                        dungeon[newCenterY][col] = '.';
                    }
                }
            }

            rooms.push_back(newRoom);
        }
    }

    for (const auto& row : dungeon) {
        for (char cell : row) {
            cout << cell;
        }
        cout << endl;
    }

    return 0;
}
```


Solution Reasoning
JavaScript - pt-PT
Sou um programador que est√° a trabalhar num sistema de convers√£o de moedas para uma aplica√ß√£o financeira. Recentemente, implementei uma fun√ß√£o em JavaScript para calcular as taxas de c√¢mbio entre diferentes moedas. Agora, preciso de analisar cautelosamente esta solu√ß√£o para garantir que funcione corretemente e de forma eficiente. Aqui est√° o c√≥digo que implementei:

```javascript
function calcularTaxaCambio(moedaBase, moedaAlvo, taxas) {
  if (moedaBase === moedaAlvo) {
    return 1;
  }

  if (taxas[moedaBase] && taxas[moedaBase][moedaAlvo]) {
    return taxas[moedaBase][moedaAlvo];
  }

  for (let moedaIntermediaria in taxas[moedaBase]) {
    if (taxas[moedaIntermediaria] && taxas[moedaIntermediaria][moedaAlvo]) {
      return taxas[moedaBase][moedaIntermediaria] * taxas[moedaIntermediaria][moedaAlvo];
    }
  }

  throw new Error("N√£o foi poss√≠vel calcular a taxa de c√¢mbio");
}
```

Por favor, analise esta fun√ß√£o passo a passo, explicando como funciona e discutindo sua efici√™ncia. Considere os seguintes pontos na sua analise:
- Como a fun√ß√£o lida com diferentes cen√°rios de convers√£o de moeda?
- Qual √© a complexidade temporal e espacial da solu√ß√£o?
- Existem potenciais problemas ou limita√ß√µes?
- Como a solu√ß√£o se compara com outras poss√≠veis abordagens?
- Que melhorias ou otimiza√ß√µes poderiam ser feitas para tornar essa fun√ß√£o mais robusta ou eficiente?

SOON‚Ñ¢Ô∏è more examples 

